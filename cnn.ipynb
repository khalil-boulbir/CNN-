{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2cff0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e72d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/trainset.hdf5', \"r\")\n",
    "    X_train = np.array(train_dataset[\"X_train\"][:]) # your train set features\n",
    "    y_train = np.array(train_dataset[\"Y_train\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/testset.hdf5', \"r\")\n",
    "    X_test = np.array(test_dataset[\"X_test\"][:]) # your train set features\n",
    "    y_test = np.array(test_dataset[\"Y_test\"][:]) # your train set labels\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d8572ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9ea91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f6e9637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(-1,28,28,1)\n",
    "X_test=X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4268a773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1cdd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=(X_train-X_train.min())/X_train.max()\n",
    "X_test=(X_test-X_train.min())/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26361e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max(),X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07c1c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(keras.layers.Input((28,28,1)))\n",
    "model.add(keras.layers.Conv2D(8,(3,3),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(16,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77578f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 13, 13, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 13, 13, 8)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 13, 13, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 6, 6, 16)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               57700     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,958\n",
      "Trainable params: 59,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa3be60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1875/1875 [==============================] - 133s 67ms/step - loss: 0.4124 - accuracy: 0.8694\n",
      "Epoch 2/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.1857 - accuracy: 0.9438\n",
      "Epoch 3/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.1463 - accuracy: 0.9557\n",
      "Epoch 4/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.1243 - accuracy: 0.9630\n",
      "Epoch 5/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.1137 - accuracy: 0.9658\n",
      "Epoch 6/300\n",
      "1875/1875 [==============================] - 127s 67ms/step - loss: 0.1028 - accuracy: 0.9689\n",
      "Epoch 7/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0936 - accuracy: 0.9714\n",
      "Epoch 8/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0904 - accuracy: 0.9727\n",
      "Epoch 9/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0829 - accuracy: 0.9750\n",
      "Epoch 10/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0828 - accuracy: 0.9744\n",
      "Epoch 11/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0799 - accuracy: 0.9761\n",
      "Epoch 12/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0776 - accuracy: 0.9769\n",
      "Epoch 13/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0739 - accuracy: 0.9778\n",
      "Epoch 14/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0737 - accuracy: 0.9778\n",
      "Epoch 15/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0720 - accuracy: 0.9778\n",
      "Epoch 16/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0674 - accuracy: 0.9794\n",
      "Epoch 17/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0695 - accuracy: 0.9795\n",
      "Epoch 18/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0662 - accuracy: 0.9795\n",
      "Epoch 19/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0643 - accuracy: 0.9803\n",
      "Epoch 20/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0655 - accuracy: 0.9803\n",
      "Epoch 21/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0627 - accuracy: 0.9806\n",
      "Epoch 22/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0637 - accuracy: 0.9804\n",
      "Epoch 23/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0643 - accuracy: 0.9803\n",
      "Epoch 24/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0626 - accuracy: 0.9804\n",
      "Epoch 25/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0600 - accuracy: 0.9817\n",
      "Epoch 26/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0595 - accuracy: 0.9809\n",
      "Epoch 27/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0582 - accuracy: 0.9821\n",
      "Epoch 28/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0596 - accuracy: 0.9815\n",
      "Epoch 29/300\n",
      "1875/1875 [==============================] - 130s 70ms/step - loss: 0.0552 - accuracy: 0.9829\n",
      "Epoch 30/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0588 - accuracy: 0.9820\n",
      "Epoch 31/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0575 - accuracy: 0.9820\n",
      "Epoch 32/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0559 - accuracy: 0.9829\n",
      "Epoch 33/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0565 - accuracy: 0.9821\n",
      "Epoch 34/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0578 - accuracy: 0.9830\n",
      "Epoch 35/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0576 - accuracy: 0.9818\n",
      "Epoch 36/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0571 - accuracy: 0.9820\n",
      "Epoch 37/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0542 - accuracy: 0.9829\n",
      "Epoch 38/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0539 - accuracy: 0.9829\n",
      "Epoch 39/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0540 - accuracy: 0.9831\n",
      "Epoch 40/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0564 - accuracy: 0.9830\n",
      "Epoch 41/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0551 - accuracy: 0.9830\n",
      "Epoch 42/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0555 - accuracy: 0.9827\n",
      "Epoch 43/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0550 - accuracy: 0.9833\n",
      "Epoch 44/300\n",
      "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0516 - accuracy: 0.9836\n",
      "Epoch 45/300\n",
      "1875/1875 [==============================] - 132s 70ms/step - loss: 0.0553 - accuracy: 0.9829\n",
      "Epoch 46/300\n",
      "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0547 - accuracy: 0.9835\n",
      "Epoch 47/300\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0535 - accuracy: 0.9836\n",
      "Epoch 48/300\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0517 - accuracy: 0.9840\n",
      "Epoch 49/300\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0499 - accuracy: 0.9847\n",
      "Epoch 50/300\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0524 - accuracy: 0.9840\n",
      "Epoch 51/300\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0498 - accuracy: 0.9842\n",
      "Epoch 52/300\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0514 - accuracy: 0.9840\n",
      "Epoch 53/300\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0521 - accuracy: 0.9836\n",
      "Epoch 54/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0507 - accuracy: 0.9842\n",
      "Epoch 55/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0510 - accuracy: 0.9840\n",
      "Epoch 56/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0504 - accuracy: 0.9843\n",
      "Epoch 57/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0532 - accuracy: 0.9840\n",
      "Epoch 58/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0524 - accuracy: 0.9845\n",
      "Epoch 59/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0495 - accuracy: 0.9845\n",
      "Epoch 60/300\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.0511 - accuracy: 0.9842\n",
      "Epoch 61/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0502 - accuracy: 0.9848\n",
      "Epoch 62/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0510 - accuracy: 0.9838\n",
      "Epoch 63/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0497 - accuracy: 0.9845\n",
      "Epoch 64/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0476 - accuracy: 0.9853\n",
      "Epoch 65/300\n",
      "1875/1875 [==============================] - 136s 73ms/step - loss: 0.0491 - accuracy: 0.9841\n",
      "Epoch 66/300\n",
      "1875/1875 [==============================] - 136s 73ms/step - loss: 0.0526 - accuracy: 0.9845\n",
      "Epoch 67/300\n",
      "1875/1875 [==============================] - 136s 73ms/step - loss: 0.0478 - accuracy: 0.9856\n",
      "Epoch 68/300\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.0520 - accuracy: 0.9840\n",
      "Epoch 69/300\n",
      "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0488 - accuracy: 0.9852\n",
      "Epoch 70/300\n",
      "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0490 - accuracy: 0.9851\n",
      "Epoch 71/300\n",
      "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0496 - accuracy: 0.9850\n",
      "Epoch 72/300\n",
      "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0493 - accuracy: 0.9852\n",
      "Epoch 73/300\n",
      "1875/1875 [==============================] - 137s 73ms/step - loss: 0.0492 - accuracy: 0.9848\n",
      "Epoch 74/300\n",
      "1875/1875 [==============================] - 138s 74ms/step - loss: 0.0487 - accuracy: 0.9845\n",
      "Epoch 75/300\n",
      "1875/1875 [==============================] - 138s 74ms/step - loss: 0.0487 - accuracy: 0.9851\n",
      "Epoch 76/300\n",
      "1875/1875 [==============================] - 139s 74ms/step - loss: 0.0514 - accuracy: 0.9838\n",
      "Epoch 77/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0482 - accuracy: 0.9848\n",
      "Epoch 78/300\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 0.0495 - accuracy: 0.9847\n",
      "Epoch 79/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0473 - accuracy: 0.9855\n",
      "Epoch 80/300\n",
      "1875/1875 [==============================] - 123s 66ms/step - loss: 0.0473 - accuracy: 0.9854\n",
      "Epoch 81/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0481 - accuracy: 0.9850\n",
      "Epoch 82/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0460 - accuracy: 0.9857\n",
      "Epoch 83/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0468 - accuracy: 0.9857\n",
      "Epoch 84/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0497 - accuracy: 0.9855\n",
      "Epoch 85/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0481 - accuracy: 0.9847\n",
      "Epoch 86/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0496 - accuracy: 0.9846\n",
      "Epoch 87/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0481 - accuracy: 0.9851\n",
      "Epoch 88/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0461 - accuracy: 0.9857\n",
      "Epoch 89/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0485 - accuracy: 0.9848\n",
      "Epoch 90/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0492 - accuracy: 0.9847\n",
      "Epoch 91/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0468 - accuracy: 0.9854\n",
      "Epoch 92/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0487 - accuracy: 0.9853\n",
      "Epoch 93/300\n",
      "1875/1875 [==============================] - 122s 65ms/step - loss: 0.0463 - accuracy: 0.9855\n",
      "Epoch 94/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0456 - accuracy: 0.9854\n",
      "Epoch 95/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0493 - accuracy: 0.9851\n",
      "Epoch 96/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0467 - accuracy: 0.9852\n",
      "Epoch 97/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0484 - accuracy: 0.9848\n",
      "Epoch 98/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0462 - accuracy: 0.9861\n",
      "Epoch 99/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0499 - accuracy: 0.9850\n",
      "Epoch 100/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0506 - accuracy: 0.9851\n",
      "Epoch 101/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0461 - accuracy: 0.9862\n",
      "Epoch 102/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0478 - accuracy: 0.9852\n",
      "Epoch 103/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0462 - accuracy: 0.9853\n",
      "Epoch 104/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0472 - accuracy: 0.9855\n",
      "Epoch 105/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0485 - accuracy: 0.9850\n",
      "Epoch 106/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0483 - accuracy: 0.9850\n",
      "Epoch 107/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0490 - accuracy: 0.9842\n",
      "Epoch 108/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0479 - accuracy: 0.9856\n",
      "Epoch 109/300\n",
      "1875/1875 [==============================] - 123s 65ms/step - loss: 0.0479 - accuracy: 0.9854\n",
      "Epoch 110/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0455 - accuracy: 0.9866\n",
      "Epoch 111/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 112/300\n",
      "1875/1875 [==============================] - 123s 66ms/step - loss: 0.0480 - accuracy: 0.9849\n",
      "Epoch 113/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0491 - accuracy: 0.9849\n",
      "Epoch 114/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0464 - accuracy: 0.9851\n",
      "Epoch 115/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0475 - accuracy: 0.9858\n",
      "Epoch 116/300\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 0.0469 - accuracy: 0.9857\n",
      "Epoch 117/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0456 - accuracy: 0.9857\n",
      "Epoch 118/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0472 - accuracy: 0.9857\n",
      "Epoch 119/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0454 - accuracy: 0.9860\n",
      "Epoch 120/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0476 - accuracy: 0.9854\n",
      "Epoch 121/300\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 0.0460 - accuracy: 0.9858\n",
      "Epoch 122/300\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.0454 - accuracy: 0.9862\n",
      "Epoch 123/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0463 - accuracy: 0.9851\n",
      "Epoch 124/300\n",
      "1875/1875 [==============================] - 128s 69ms/step - loss: 0.0496 - accuracy: 0.9849\n",
      "Epoch 125/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0462 - accuracy: 0.9854\n",
      "Epoch 126/300\n",
      "1875/1875 [==============================] - 123s 66ms/step - loss: 0.0448 - accuracy: 0.9863\n",
      "Epoch 127/300\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0475 - accuracy: 0.9850\n",
      "Epoch 128/300\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.0440 - accuracy: 0.9864\n",
      "Epoch 129/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0495 - accuracy: 0.9851\n",
      "Epoch 130/300\n",
      "1875/1875 [==============================] - 130s 70ms/step - loss: 0.0471 - accuracy: 0.9862\n",
      "Epoch 131/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0480 - accuracy: 0.9852\n",
      "Epoch 132/300\n",
      "1875/1875 [==============================] - 121s 65ms/step - loss: 0.0469 - accuracy: 0.9855\n",
      "Epoch 133/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0450 - accuracy: 0.9858\n",
      "Epoch 134/300\n",
      "1875/1875 [==============================] - 105s 56ms/step - loss: 0.0469 - accuracy: 0.9856\n",
      "Epoch 135/300\n",
      "1875/1875 [==============================] - 162s 70ms/step - loss: 0.0475 - accuracy: 0.9850\n",
      "Epoch 136/300\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.0484 - accuracy: 0.9859\n",
      "Epoch 137/300\n",
      "1875/1875 [==============================] - 124s 66ms/step - loss: 0.0444 - accuracy: 0.9865\n",
      "Epoch 138/300\n",
      "1875/1875 [==============================] - 172s 73ms/step - loss: 0.0451 - accuracy: 0.9861\n",
      "Epoch 139/300\n",
      "1875/1875 [==============================] - 121s 64ms/step - loss: 0.0452 - accuracy: 0.9861\n",
      "Epoch 140/300\n",
      "1875/1875 [==============================] - 128s 69ms/step - loss: 0.0474 - accuracy: 0.9851\n",
      "Epoch 141/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0475 - accuracy: 0.9854\n",
      "Epoch 142/300\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.0462 - accuracy: 0.9858\n",
      "Epoch 143/300\n",
      "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0457 - accuracy: 0.9859\n",
      "Epoch 144/300\n",
      "1144/1875 [=================>............] - ETA: 43s - loss: 0.0477 - accuracy: 0.9850Epoch 145/300\n",
      "1875/1875 [==============================] - 308s 146ms/step - loss: 0.0473 - accuracy: 0.9852\n",
      "Epoch 146/300\n",
      "1875/1875 [==============================] - 192s 74ms/step - loss: 0.0472 - accuracy: 0.9860\n",
      "Epoch 147/300\n",
      "1875/1875 [==============================] - 122s 65ms/step - loss: 0.0474 - accuracy: 0.9859\n",
      "Epoch 148/300\n",
      "1875/1875 [==============================] - 120s 64ms/step - loss: 0.0457 - accuracy: 0.9861\n",
      "Epoch 149/300\n",
      "1875/1875 [==============================] - 132s 71ms/step - loss: 0.0485 - accuracy: 0.9852\n",
      "Epoch 150/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0445 - accuracy: 0.9859\n",
      "Epoch 151/300\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.0455 - accuracy: 0.9853\n",
      "Epoch 152/300\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.0443 - accuracy: 0.9862\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 120s 64ms/step - loss: 0.0474 - accuracy: 0.9849\n",
      "Epoch 154/300\n",
      "1875/1875 [==============================] - 121s 65ms/step - loss: 0.0459 - accuracy: 0.9859\n",
      "Epoch 155/300\n",
      "1875/1875 [==============================] - 123s 66ms/step - loss: 0.0468 - accuracy: 0.9862\n",
      "Epoch 156/300\n",
      "1479/1875 [======================>.......] - ETA: 23s - loss: 0.0447 - accuracy: 0.9856"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b45d8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 11s 31ms/step - loss: 7.6879 - accuracy: 0.9813\n",
      "loss is 7.687867164611816\n",
      "accuracy is 0.9812999963760376\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,y_test)\n",
    "print(\"loss is\",score[0])\n",
    "print(\"accuracy is\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a01b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 31ms/step\n",
      "[7 2 1 0 4 1 4 9 5 9]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = model.predict(X_test)\n",
    "predictions = np.argmax(predict_proba, axis=1)\n",
    "print(predictions[:10])\n",
    "print(y_test[:10])\n",
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03047f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 4))\n",
    "ax.imshow(X_train[241], cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4cfb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
